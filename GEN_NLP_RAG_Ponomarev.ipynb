{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Генеративные задачи в NLP II"
      ],
      "metadata": {
        "id": "xmtddPPepigX"
      },
      "id": "xmtddPPepigX"
    },
    {
      "cell_type": "markdown",
      "id": "intro-header-v5",
      "metadata": {
        "id": "intro-header-v5"
      },
      "source": [
        "# Методы RAG: поэтапное тестирование конфигураций\n",
        "## Тестовый пайплайн с расширенной оценкой\n",
        "\n",
        "Этот проект создан для понимания того, как различные настройки влияют на системы Retrieval-Augmented Generation (RAG). Мы построим и протестируем пайплайн шаг за шагом с использованием **Nebius AI API**.\n",
        "\n",
        "**Что предстоит выяснить:**\n",
        "*   Как нарезка текста (`chunk_size`, `chunk_overlap`) влияет на то, какие данные извлекает система RAG.\n",
        "*   Как количество извлекаемых документов (`top_k`) влияет на контекст, передаваемый LLM.\n",
        "*   В чем разница между тремя распространёнными стратегиями RAG (Simple, Query Rewrite, Rerank).\n",
        "*   Как использовать LLM (например, Nebius AI) для автоматической оценки качества сгенерированных ответов по нескольким метрикам: **Достоверность** (Faithfulness), **Релевантность** (Relevancy) и **Семантическое сходство** (Semantic Similarity) с эталонным ответом.\n",
        "*   Как объединить эти метрики в средний балл для удобства сравнения.\n",
        "\n",
        "Мы сосредоточимся на понимании *зачем* выполняется каждый шаг и будем чётко наблюдать результаты, с подробными объяснениями и комментированным кодом.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "toc-v5",
      "metadata": {
        "id": "toc-v5"
      },
      "source": [
        "### Оглавление\n",
        "1.  **Настройка: Установка библиотек**: Получаем необходимые инструменты.\n",
        "2.  **Настройка: Импорт библиотек**: Подключаем инструменты в рабочее пространство.\n",
        "3.  **Конфигурация: Подготовка эксперимента**: Определяем параметры API, модели, запросы для оценки и параметры тестирования.\n",
        "4.  **Входные данные: Источник знаний и наш вопрос**: Определяем документы, из которых будет учиться система RAG, и формулируем вопрос.\n",
        "5.  **Ключевой компонент: Функция нарезки текста**: Создаем функцию для разбиения документов на небольшие части.\n",
        "6.  **Ключевой компонент: Подключение к Nebius AI**: Устанавливаем соединение для использования моделей Nebius.\n",
        "7.  **Ключевой компонент: Функция косинусного сходства**: Создаем функцию для измерения семантического сходства между текстами.\n",
        "8.  **Эксперимент: Перебор конфигураций**: Основной цикл, в котором тестируются разные настройки.\n",
        "    *   8.1 Обработка конфигурации нарезки (Chunk, Embed, Index)\n",
        "    *   8.2 Тестирование стратегий RAG для значения `top_k`\n",
        "    *   8.3 Запуск и оценка отдельной стратегии RAG (включая сходство)\n",
        "9.  **Анализ: Анализ результатов**: Используем Pandas для организации и отображения результатов.\n",
        "10. **Выводы: Что мы узнали?**: Рефлексия по итогам и возможные следующие шаги.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-install-v5",
      "metadata": {
        "id": "setup-install-v5"
      },
      "source": [
        "### 1. Настройка: Установка библиотек\n",
        "\n",
        "Сначала нужно установить Python-библиотеки, необходимые для работы в этом ноутбуке.\n",
        "- `openai`: Для взаимодействия с Nebius API (он использует совместимый с OpenAI интерфейс).\n",
        "- `pandas`: Для создания и управления таблицами данных (DataFrame).\n",
        "- `numpy`: Для числовых операций, особенно с векторами (эмбеддингами).\n",
        "- `faiss-cpu`: Для эффективного поиска похожих векторов (этап извлечения информации).\n",
        "- `ipywidgets`, `tqdm`: Для отображения индикаторов выполнения в Jupyter.\n",
        "- `scikit-learn`: Для расчёта косинусного сходства.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "install-libs-v5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "install-libs-v5",
        "outputId": "e328fcf1-961d-482c-b5ed-fd9e7513a414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.84.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.8.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.24.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.25.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0 jedi-0.19.2\n"
          ]
        }
      ],
      "source": [
        "# Установка библиотек (запустите эту ячейку только один раз при необходимости)\n",
        "!pip install openai pandas numpy faiss-cpu ipywidgets tqdm scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "install-note-v5",
      "metadata": {
        "id": "install-note-v5"
      },
      "source": [
        "**Обратите внимание!** После завершения установки может потребоваться **перезапустить ядро** (или среду выполнения), чтобы Jupyter/Colab распознал новые библиотеки.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-import-v5",
      "metadata": {
        "id": "setup-import-v5"
      },
      "source": [
        "### 2. Настройка: Импорт библиотек\n",
        "\n",
        "После установки библиотек импортируем их в наше Python-окружение, чтобы сделать их функции доступными для использования.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "import-code-v5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "import-code-v5",
        "outputId": "f6203c2e-91ea-4b2e-b43a-39e3a109671d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Библиотеки успешно импортированы!\n"
          ]
        }
      ],
      "source": [
        "import os                     # Для доступа к переменным окружения (например, API-ключи)\n",
        "import time                   # Для замера времени выполнения операций\n",
        "import re                     # Для работы с регулярными выражениями (очистка текста)\n",
        "import warnings               # Для управления предупреждающими сообщениями\n",
        "import itertools              # Для удобного создания комбинаций параметров\n",
        "import getpass                # Для безопасного ввода API-ключей, если они не заданы\n",
        "\n",
        "import numpy as np            # Числовая библиотека для работы с векторами\n",
        "import pandas as pd           # Библиотека для обработки и анализа таблиц (DataFrame)\n",
        "import faiss                  # Библиотека для быстрого поиска схожих векторов\n",
        "from openai import OpenAI     # Клиентская библиотека для взаимодействия с Nebius API\n",
        "from tqdm.notebook import tqdm # Для отображения прогресс-баров\n",
        "from sklearn.metrics.pairwise import cosine_similarity # Для расчёта метрики схожести\n",
        "\n",
        "# Настройка параметров отображения для Pandas DataFrame для удобства чтения\n",
        "pd.set_option('display.max_colwidth', 150) # Показывать больше текста в ячейках таблицы\n",
        "pd.set_option('display.max_rows', 100)     # Показывать больше строк в таблицах\n",
        "warnings.filterwarnings('ignore', category=FutureWarning) # Отключить определённые некритичные предупреждения\n",
        "\n",
        "print(\"Библиотеки успешно импортированы!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "config-params-v5",
      "metadata": {
        "id": "config-params-v5"
      },
      "source": [
        "### 3. Конфигурация: Настройка эксперимента\n",
        "\n",
        "Здесь мы определяем все настройки и параметры для нашего эксперимента напрямую как переменные Python. Это удобно — вся конфигурация собрана в одном месте, её легко просматривать и изменять.\n",
        "\n",
        "**Основные блоки конфигурации:**\n",
        "*   **Данные для Nebius API:** Учётные данные и идентификаторы моделей для подключения к Nebius AI.\n",
        "*   **Параметры LLM:** Настройки, управляющие поведением языковой модели при генерации ответа (например, `temperature` — уровень креативности).\n",
        "*   **Промпты для оценки:** Конкретные инструкции (промпты), которые LLM получает для оценки Достоверности и Релевантности.\n",
        "*   **Параметры для настройки:** Различные значения для размера чанка, перекрытия и количества извлекаемых документов (`top_k`), которые мы будем систематически тестировать.\n",
        "*   **Настройки ранжирования:** Конфигурация для имитации стратегии повторного ранжирования.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "config-setup-v5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "config-setup-v5",
        "outputId": "451a2b8a-6ba7-4480-a56e-6098ec953f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Внимание: NEBIUS_API_KEY не задан. Пожалуйста, установите его в переменных окружения или укажите напрямую в коде.\n",
            "--- Проверка конфигурации --- \n",
            "Пробуем загрузить Nebius API Key из переменной окружения 'NEBIUS_API_KEY'...\n",
            "Nebius API Key не найден в переменных окружения.\n",
            "Пожалуйста, введите свой Nebius API Key: ··········\n",
            "Модели: Embed='BAAI/bge-multilingual-gemma2', Gen='deepseek-ai/DeepSeek-V3', Eval='deepseek-ai/DeepSeek-V3'\n",
            "Тестируемые размеры чанков: [150, 250]\n",
            "Тестируемые значения перекрытия: [30, 50]\n",
            "Тестируемые значения Top-K: [3, 5]\n",
            "Температура генерации: 0.1, Макс. токенов: 400\n",
            "Конфигурация готова.\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "# --- Конфигурация API NebiusAI ---\n",
        "# Рекомендуется хранить API-ключи в переменных окружения, а не прописывать их напрямую в коде.\n",
        "# Укажите свой настоящий ключ здесь или задайте его как переменную окружения\n",
        "NEBIUS_API_KEY = os.getenv('NEBIUS_API_KEY', None)  # Загружаем API-ключ из переменной окружения\n",
        "if NEBIUS_API_KEY is None:\n",
        "    print(\"Внимание: NEBIUS_API_KEY не задан. Пожалуйста, установите его в переменных окружения или укажите напрямую в коде.\")\n",
        "NEBIUS_BASE_URL = \"https://api.studio.nebius.com/v1/\"\n",
        "NEBIUS_EMBEDDING_MODEL = \"BAAI/bge-multilingual-gemma2\"  # Модель для преобразования текста в векторные эмбеддинги\n",
        "NEBIUS_GENERATION_MODEL = \"deepseek-ai/DeepSeek-V3\"      # LLM для генерации итоговых ответов\n",
        "NEBIUS_EVALUATION_MODEL = \"deepseek-ai/DeepSeek-V3\"      # LLM для оценки сгенерированных ответов\n",
        "\n",
        "# --- Параметры генерации текста (для генерации ответа RAG) ---\n",
        "GENERATION_TEMPERATURE = 0.1  # Меньшие значения (например, 0.1-0.3) делают ответ более точным и менее случайным, хорошо для фактических ответов.\n",
        "GENERATION_MAX_TOKENS = 400   # Максимальное количество токенов (примерно слов/частей слов) в сгенерированном ответе.\n",
        "GENERATION_TOP_P = 0.9        # Параметр nucleus sampling (обычно достаточно значения по умолчанию).\n",
        "\n",
        "# --- Промпты для оценки (инструкции для оценщика LLM) ---\n",
        "# Достоверность: Насколько ответ соответствует предоставленному контексту?\n",
        "FAITHFULNESS_PROMPT = \"\"\"\n",
        "System: You are an objective evaluator. Evaluate the faithfulness of the AI Response compared to the True Answer, considering only the information present in the True Answer as the ground truth.\n",
        "Faithfulness measures how accurately the AI response reflects the information in the True Answer, without adding unsupported facts or contradicting it.\n",
        "Score STRICTLY using a float between 0.0 and 1.0, based on this scale:\n",
        "- 0.0: Completely unfaithful, contradicts or fabricates information.\n",
        "- 0.1-0.4: Low faithfulness with significant inaccuracies or unsupported claims.\n",
        "- 0.5-0.6: Partially faithful but with noticeable inaccuracies or omissions.\n",
        "- 0.7-0.8: Mostly faithful with only minor inaccuracies or phrasing differences.\n",
        "- 0.9: Very faithful, slight wording differences but semantically aligned.\n",
        "- 1.0: Completely faithful, accurately reflects the True Answer.\n",
        "Respond ONLY with the numerical score.\n",
        "\n",
        "User:\n",
        "Query: {question}\n",
        "AI Response: {response}\n",
        "True Answer: {true_answer}\n",
        "Score:\"\"\"\n",
        "\n",
        "# Релевантность: Насколько ответ напрямую отвечает на вопрос пользователя?\n",
        "RELEVANCY_PROMPT = \"\"\"\n",
        "System: You are an objective evaluator. Evaluate the relevance of the AI Response to the specific User Query.\n",
        "Relevancy measures how well the response directly answers the user's question, avoiding unnecessary or off-topic information.\n",
        "Score STRICTLY using a float between 0.0 and 1.0, based on this scale:\n",
        "- 0.0: Not relevant at all.\n",
        "- 0.1-0.4: Low relevance, addresses a different topic or misses the core question.\n",
        "- 0.5-0.6: Partially relevant, answers only a part of the query or is tangentially related.\n",
        "- 0.7-0.8: Mostly relevant, addresses the main aspects of the query but might include minor irrelevant details.\n",
        "- 0.9: Highly relevant, directly answers the query with minimal extra information.\n",
        "- 1.0: Completely relevant, directly and fully answers the exact question asked.\n",
        "Respond ONLY with the numerical score.\n",
        "\n",
        "User:\n",
        "Query: {question}\n",
        "AI Response: {response}\n",
        "Score:\"\"\"\n",
        "\n",
        "# --- Настраиваемые параметры (экспериментальные переменные) ---\n",
        "CHUNK_SIZES_TO_TEST = [150, 250]    # Список размеров чанков (в словах) для тестирования.\n",
        "CHUNK_OVERLAPS_TO_TEST = [30, 50]   # Список перекрытий чанков (в словах) для тестирования.\n",
        "RETRIEVAL_TOP_K_TO_TEST = [3, 5]    # Список значений 'k' (количество чанков для поиска), которые будем тестировать.\n",
        "\n",
        "# --- Конфигурация повторного ранжирования (используется только для стратегии Rerank) ---\n",
        "RERANK_RETRIEVAL_MULTIPLIER = 3 # Для симулированного ранжирования: сначала извлекаем K * multiplier чанков.\n",
        "\n",
        "# --- Проверка API-ключа ---\n",
        "print(\"--- Проверка конфигурации --- \")\n",
        "print(f\"Пробуем загрузить Nebius API Key из переменной окружения 'NEBIUS_API_KEY'...\")\n",
        "if not NEBIUS_API_KEY:\n",
        "    print(\"Nebius API Key не найден в переменных окружения.\")\n",
        "    # Запросить ключ у пользователя, если не найден.\n",
        "    NEBIUS_API_KEY = getpass.getpass(\"Пожалуйста, введите свой Nebius API Key: \")\n",
        "else:\n",
        "    print(\"Nebius API Key успешно загружен из переменной окружения.\")\n",
        "\n",
        "# Вывод краткой информации о настройках для проверки\n",
        "print(f\"Модели: Embed='{NEBIUS_EMBEDDING_MODEL}', Gen='{NEBIUS_GENERATION_MODEL}', Eval='{NEBIUS_EVALUATION_MODEL}'\")\n",
        "print(f\"Тестируемые размеры чанков: {CHUNK_SIZES_TO_TEST}\")\n",
        "print(f\"Тестируемые значения перекрытия: {CHUNK_OVERLAPS_TO_TEST}\")\n",
        "print(f\"Тестируемые значения Top-K: {RETRIEVAL_TOP_K_TO_TEST}\")\n",
        "print(f\"Температура генерации: {GENERATION_TEMPERATURE}, Макс. токенов: {GENERATION_MAX_TOKENS}\")\n",
        "print(\"Конфигурация готова.\")\n",
        "print(\"-\" * 25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "input-data-v5",
      "metadata": {
        "id": "input-data-v5"
      },
      "source": [
        "### 4. Входные данные: Источник знаний и наш вопрос\n",
        "\n",
        "Любая система RAG нуждается в базе знаний, из которой будет извлекаться информация. Здесь мы определяем:\n",
        "*   `corpus_texts`: Список строк, где каждая строка — это документ с информацией (в данном случае, об источниках возобновляемой энергии).\n",
        "*   `test_query`: Конкретный вопрос, на который мы хотим получить ответ от системы RAG, используя `corpus_texts`.\n",
        "*   `true_answer_for_query`: Тщательно сформулированный «эталонный» ответ, основанный *только* на информации из `corpus_texts`. Это важно для точной оценки достоверности (Faithfulness) и семантического сходства (Semantic Similarity)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "corpus-def-v5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "corpus-def-v5",
        "outputId": "a613846c-9054-4bb5-e6cf-6db28b654089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загружено 5 документов в наш корпус.\n",
            "Тестовый вопрос: 'Compare the consistency and environmental impact of solar power versus hydropower.'\n",
            "Эталонный (True) ответ для оценки: 'Solar power's consistency varies with weather and time of day, requiring storage like batteries. Hydropower is generally reliable, but large dams have significant environmental impacts on ecosystems and communities, unlike solar power's primary impact being land use for panels.'\n",
            "Входные данные готовы.\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "# Наша база знаний: список текстовых документов об альтернативной энергетике\n",
        "corpus_texts = [\n",
        "    \"Solar power uses PV panels or CSP systems. PV converts sunlight directly to electricity. CSP uses mirrors to heat fluid driving a turbine. It's clean but varies with weather/time. Storage (batteries) is key for consistency.\", # Документ 0\n",
        "    \"Wind energy uses turbines in wind farms. It's sustainable with low operating costs. Wind speed varies, siting can be challenging (visual/noise). Offshore wind is stronger and more consistent.\", # Документ 1\n",
        "    \"Hydropower uses moving water, often via dams spinning turbines. Reliable, large-scale power with flood control/water storage benefits. Big dams harm ecosystems and displace communities. Run-of-river is smaller, less disruptive.\", # Документ 2\n",
        "    \"Geothermal energy uses Earth's heat via steam/hot water for turbines. Consistent 24/7 power, small footprint. High initial drilling costs, sites are geographically limited.\", # Документ 3\n",
        "    \"Biomass energy from organic matter (wood, crops, waste). Burned directly or converted to biofuels. Uses waste, provides dispatchable power. Requires sustainable sourcing. Combustion releases emissions (carbon-neutral if balanced by regrowth).\" # Документ 4\n",
        "]\n",
        "\n",
        "# Вопрос, который мы зададим системе RAG\n",
        "test_query = \"Compare the consistency and environmental impact of solar power versus hydropower.\"\n",
        "\n",
        "# !!! ВАЖНО: 'True Answer' ДОЛЖЕН быть выведен ТОЛЬКО из corpus_texts выше !!!\n",
        "# Это наш эталон для оценки.\n",
        "true_answer_for_query = \"Solar power's consistency varies with weather and time of day, requiring storage like batteries. Hydropower is generally reliable, but large dams have significant environmental impacts on ecosystems and communities, unlike solar power's primary impact being land use for panels.\"\n",
        "\n",
        "print(f\"Загружено {len(corpus_texts)} документов в наш корпус.\")\n",
        "print(f\"Тестовый вопрос: '{test_query}'\")\n",
        "print(f\"Эталонный (True) ответ для оценки: '{true_answer_for_query}'\")\n",
        "print(\"Входные данные готовы.\")\n",
        "print(\"-\" * 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chunking-func-md-v5",
      "metadata": {
        "id": "chunking-func-md-v5"
      },
      "source": [
        "### 5. Ключевой компонент: Функция нарезки текста на чанки\n",
        "\n",
        "LLM и модели эмбеддингов имеют ограничения на объём текста, который они могут обрабатывать за раз. Кроме того, поиск работает лучше, когда он проводится по небольшим, сфокусированным кускам текста, а не по целым большим документам.\n",
        "\n",
        "**Нарезка на чанки** — это процесс разделения больших документов на более мелкие, возможно, пересекающиеся сегменты.\n",
        "\n",
        "- **`chunk_size`**: Определяет примерный размер (здесь — в словах) каждого чанка.\n",
        "- **`chunk_overlap`**: Задает, сколько слов с конца одного чанка также будут включены в начало следующего чанка. Это помогает не потерять важную информацию, если она находится на границе между двумя чанками.\n",
        "\n",
        "Мы определяем функцию `chunk_text` для такого разбиения на основе количества слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "chunking-func-v5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chunking-func-v5",
        "outputId": "e40ece74-b88f-4789-afa9-001b3e878dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Определена функция 'chunk_text'.\n",
            "Тест нарезки на первом документе (размер=150 слов, перекрытие=30 слов): Создано чанков: 1.\n",
            "Пример первого чанка:\n",
            "'Solar power uses PV panels or CSP systems. PV converts sunlight directly to electricity. CSP uses mirrors to heat fluid driving a turbine. It's clean but varies with weather/time. Storage (batteries) is key for consistency.'\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "def chunk_text(text, chunk_size, chunk_overlap):\n",
        "    \"\"\"Разбивает один текстовый документ на пересекающиеся чанки по количеству слов.\n",
        "\n",
        "    Args:\n",
        "        text (str): Входной текст для нарезки.\n",
        "        chunk_size (int): Желаемое количество слов в одном чанке.\n",
        "        chunk_overlap (int): Количество слов, которое будет пересекаться между соседними чанками.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: Список текстовых чанков.\n",
        "    \"\"\"\n",
        "    words = text.split()      # Разделяем текст на список отдельных слов\n",
        "    total_words = len(words)  # Считаем общее количество слов в тексте\n",
        "    chunks = []               # Создаем пустой список для хранения чанков\n",
        "    start_index = 0           # Начальный индекс слова для первого чанка\n",
        "\n",
        "    # --- Проверка входных данных ---\n",
        "    # Проверяем, что chunk_size — положительное целое число.\n",
        "    if not isinstance(chunk_size, int) or chunk_size <= 0:\n",
        "        print(f\"  Внимание: Некорректный chunk_size ({chunk_size}). Должен быть положительным целым числом. Возвращаем весь текст одним чанком.\")\n",
        "        return [text]\n",
        "    # Проверяем, что chunk_overlap — неотрицательное целое число, меньшее чем chunk_size.\n",
        "    if not isinstance(chunk_overlap, int) or chunk_overlap < 0:\n",
        "        print(f\"  Внимание: Некорректный chunk_overlap ({chunk_overlap}). Должен быть неотрицательным целым числом. Перекрытие установлено в 0.\")\n",
        "        chunk_overlap = 0\n",
        "    if chunk_overlap >= chunk_size:\n",
        "        # Если перекрытие слишком большое, корректируем до разумной величины (например, 1/3 от chunk_size)\n",
        "        # Это предотвращает бесконечные циклы или некорректную нарезку.\n",
        "        adjusted_overlap = chunk_size // 3\n",
        "        print(f\"  Внимание: chunk_overlap ({chunk_overlap}) >= chunk_size ({chunk_size}). Перекрытие установлено в {adjusted_overlap}.\")\n",
        "        chunk_overlap = adjusted_overlap\n",
        "\n",
        "    # --- Основной цикл нарезки ---\n",
        "    # Продолжаем нарезку, пока start_index в пределах текста\n",
        "    while start_index < total_words:\n",
        "        # Определяем конечный индекс для текущего чанка.\n",
        "        # Это минимум между (start + chunk_size) и общим количеством слов.\n",
        "        end_index = min(start_index + chunk_size, total_words)\n",
        "\n",
        "        # Извлекаем слова для текущего чанка и соединяем их обратно в строку.\n",
        "        current_chunk_text = \" \".join(words[start_index:end_index])\n",
        "        chunks.append(current_chunk_text) # Добавляем сформированный чанк в список\n",
        "\n",
        "        # Вычисляем начальный индекс для *следующего* чанка.\n",
        "        # Продвигаемся на (chunk_size - chunk_overlap) слов вперёд.\n",
        "        next_start_index = start_index + chunk_size - chunk_overlap\n",
        "\n",
        "        # --- Проверки безопасности ---\n",
        "        # Проверка 1: Предотвращение бесконечных циклов, если перекрытие мешает продвижению.\n",
        "        # Такое возможно, если chunk_size очень маленький, а перекрытие слишком большое.\n",
        "        if next_start_index <= start_index:\n",
        "            if end_index == total_words: # Если уже в конце, можно выйти из цикла.\n",
        "                break\n",
        "            else:\n",
        "                # Насильно двигаемся вперед хотя бы на одно слово.\n",
        "                print(f\"  Внимание: Логика нарезки застряла (start={start_index}, next_start={next_start_index}). Принудительно продолжаем.\")\n",
        "                next_start_index = start_index + 1\n",
        "\n",
        "        # Проверка 2: Если рассчитанный следующий индекс уже на конце или за пределами текста — выходим.\n",
        "        if next_start_index >= total_words:\n",
        "            break\n",
        "\n",
        "        # Сдвигаем start_index на следующую позицию для следующей итерации.\n",
        "        start_index = next_start_index\n",
        "\n",
        "    return chunks # Возвращаем итоговый список чанков\n",
        "\n",
        "# --- Быстрый тест ---\n",
        "# Тестируем функцию на первом документе с примерными параметрами.\n",
        "print(\"Определена функция 'chunk_text'.\")\n",
        "sample_chunk_size = 150\n",
        "sample_overlap = 30\n",
        "sample_chunks = chunk_text(corpus_texts[0], sample_chunk_size, sample_overlap)\n",
        "print(f\"Тест нарезки на первом документе (размер={sample_chunk_size} слов, перекрытие={sample_overlap} слов): Создано чанков: {len(sample_chunks)}.\")\n",
        "if sample_chunks: # Печатаем только если чанки созданы\n",
        "    print(f\"Пример первого чанка:\\n'{sample_chunks[0]}'\")\n",
        "print(\"-\" * 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "client-setup-md-v5",
      "metadata": {
        "id": "client-setup-md-v5"
      },
      "source": [
        "### 6. Ключевой компонент: Подключение к Nebius AI\n",
        "\n",
        "Для использования моделей Nebius AI (эмбеддинг, генерация, оценка) необходимо установить соединение с их API. Мы используем Python-библиотеку `openai`, которая предоставляет удобный способ взаимодействия с API, совместимыми с OpenAI, такими как Nebius.\n",
        "\n",
        "Мы создаём объект клиента `OpenAI`, указывая наш API-ключ и конкретный URL-адрес эндпоинта Nebius API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "client-setup-v5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "client-setup-v5",
        "outputId": "fa053e35-381b-426e-84a9-f14b08e33fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пробуем инициализировать клиента Nebius AI...\n",
            "Клиент Nebius AI успешно инициализирован. Готовы к работе с API.\n",
            "Шаг по настройке клиента завершён.\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "client = None # Инициализируем переменную клиента как None глобально\n",
        "\n",
        "print(\"Пробуем инициализировать клиента Nebius AI...\")\n",
        "try:\n",
        "    # Проверяем, действительно ли API-ключ доступен перед созданием клиента\n",
        "    if not NEBIUS_API_KEY:\n",
        "        raise ValueError(\"Отсутствует Nebius API Key. Невозможно инициализировать клиента.\")\n",
        "\n",
        "    # Создаем объект клиента OpenAI, настроенный для API Nebius.\n",
        "    client = OpenAI(\n",
        "        api_key=NEBIUS_API_KEY,     # Передаём ранее загруженный API-ключ\n",
        "        base_url=NEBIUS_BASE_URL    # Указываем эндпоинт API Nebius\n",
        "    )\n",
        "\n",
        "    # Необязательно: Можно добавить быструю тестовую команду для проверки соединения с клиентом,\n",
        "    # например, вывод списка моделей (если поддерживается и нужно). Может повлечь расходы.\n",
        "    # try:\n",
        "    #     client.models.list()\n",
        "    #     print(\"Соединение с клиентом успешно проверено через список моделей.\")\n",
        "    # except Exception as test_e:\n",
        "    #     print(f\"Внимание: Не удалось проверить соединение с клиентом через тестовый вызов: {test_e}\")\n",
        "\n",
        "    print(\"Клиент Nebius AI успешно инициализирован. Готовы к работе с API.\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Обработка любых ошибок во время инициализации клиента (например, неверный ключ, проблемы с сетью)\n",
        "    print(f\"Ошибка при инициализации клиента Nebius AI: {e}\")\n",
        "    print(\"!!! Невозможно продолжить выполнение без корректного клиента. Пожалуйста, проверьте API-ключ и соединение с сетью. !!!\")\n",
        "    # Устанавливаем client обратно в None, чтобы избежать дальнейших попыток при неудачной инициализации\n",
        "    client = None\n",
        "\n",
        "print(\"Шаг по настройке клиента завершён.\")\n",
        "print(\"-\" * 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "similarity-func-md-v5",
      "metadata": {
        "id": "similarity-func-md-v5"
      },
      "source": [
        "### 7. Ключевой компонент: Функция косинусного сходства\n",
        "\n",
        "Чтобы оценить, насколько сгенерированный ответ семантически похож на наш эталонный ответ, мы используем **косинусное сходство**. Эта метрика измеряет косинус угла между двумя векторами (в нашем случае — эмбеддинг-векторами двух ответов).\n",
        "\n",
        "- Оценка **1** означает, что векторы направлены в одну сторону (максимальное сходство).\n",
        "- Оценка **0** означает, что векторы ортогональны (нет сходства).\n",
        "- Оценка **-1** означает, что векторы направлены в противоположные стороны (максимальное различие).\n",
        "\n",
        "Для текстовых эмбеддингов оценки обычно варьируются от 0 до 1, где большие значения означают большее семантическое сходство.\n",
        "\n",
        "Мы определяем функцию `calculate_cosine_similarity`, которая принимает две текстовые строки, генерирует их эмбеддинги с помощью клиента Nebius и возвращает оценку их косинусного сходства."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "similarity-func-v5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "similarity-func-v5",
        "outputId": "be187c1f-b90a-4545-a363-b15730b7bcfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Определена функция 'calculate_cosine_similarity'.\n",
            "Тест функции сходства: Сходство между 'apple' и 'orange' = 0.76\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "def calculate_cosine_similarity(text1, text2, client, embedding_model):\n",
        "    \"\"\"Вычисляет косинусное сходство между эмбеддингами двух текстов.\n",
        "\n",
        "    Args:\n",
        "        text1 (str): Первая текстовая строка.\n",
        "        text2 (str): Вторая текстовая строка.\n",
        "        client (OpenAI): Инициализированный клиент Nebius AI.\n",
        "        embedding_model (str): Название используемой модели эмбеддингов.\n",
        "\n",
        "    Returns:\n",
        "        float: Оценка косинусного сходства (от 0.0 до 1.0) или 0.0 в случае ошибки.\n",
        "    \"\"\"\n",
        "    if not client:\n",
        "        print(\"  Ошибка: Клиент Nebius недоступен для расчёта сходства.\")\n",
        "        return 0.0\n",
        "    if not text1 or not text2:\n",
        "        # Обработка случая, когда одна или обе строки пустые или None\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Генерируем эмбеддинги для обоих текстов одним запросом к API, если возможно\n",
        "        response = client.embeddings.create(model=embedding_model, input=[text1, text2])\n",
        "\n",
        "        # Извлекаем векторные представления\n",
        "        embedding1 = np.array(response.data[0].embedding)\n",
        "        embedding2 = np.array(response.data[1].embedding)\n",
        "\n",
        "        # Преобразуем векторы к формату 2D, как ожидает функция cosine_similarity\n",
        "        embedding1 = embedding1.reshape(1, -1)\n",
        "        embedding2 = embedding2.reshape(1, -1)\n",
        "\n",
        "        # Считаем косинусное сходство с помощью scikit-learn\n",
        "        # cosine_similarity возвращает 2D-массив, например, [[значение]], поэтому извлекаем само значение.\n",
        "        similarity_score = cosine_similarity(embedding1, embedding2)[0][0]\n",
        "\n",
        "        # Ограничиваем значение в диапазоне от 0.0 до 1.0 для стабильности и единообразия\n",
        "        return max(0.0, min(1.0, similarity_score))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Ошибка при вычислении косинусного сходства: {e}\")\n",
        "        return 0.0 # Возвращаем 0.0 в случае любой ошибки API или вычислений\n",
        "\n",
        "# --- Быстрый тест ---\n",
        "print(\"Определена функция 'calculate_cosine_similarity'.\")\n",
        "if client: # Запуск теста только если клиент инициализирован\n",
        "    test_sim = calculate_cosine_similarity(\"apple\", \"orange\", client, NEBIUS_EMBEDDING_MODEL)\n",
        "    print(f\"Тест функции сходства: Сходство между 'apple' и 'orange' = {test_sim:.2f}\")\n",
        "else:\n",
        "    print(\"Пропускаем тест функции сходства, так как клиент Nebius не инициализирован.\")\n",
        "print(\"-\" * 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "main-loop-md-v5",
      "metadata": {
        "id": "main-loop-md-v5"
      },
      "source": [
        "### 8. Эксперимент: Перебор конфигураций\n",
        "\n",
        "В этом разделе находится основной экспериментальный цикл. Мы систематически переберём все комбинации настраиваемых параметров, определённых ранее (`CHUNK_SIZES_TO_TEST`, `CHUNK_OVERLAPS_TO_TEST`, `RETRIEVAL_TOP_K_TO_TEST`).\n",
        "\n",
        "**Рабочий процесс для каждой комбинации параметров:**\n",
        "\n",
        "1.  **Подготовка данных (Чанкирование/Эмбеддинг/Индексация — Шаг 8.1):**\n",
        "    *   **Проверка необходимости перерасчёта:** Если параметры `chunk_size` или `chunk_overlap` изменились по сравнению с предыдущей итерацией, нужно повторно обработать корпус.\n",
        "    *   **Нарезка на чанки:** Разделяем все документы из `corpus_texts` с текущими `chunk_size` и `chunk_overlap` с помощью функции `chunk_text`.\n",
        "    *   **Эмбеддинг:** Преобразуем каждый чанк текста в числовой вектор (эмбеддинг) с помощью выбранной модели Nebius (`NEBIUS_EMBEDDING_MODEL`). Для эффективности делаем это пакетно.\n",
        "    *   **Индексация:** Строим индекс FAISS (`IndexFlatL2`) из полученных эмбеддингов. FAISS позволяет очень быстро находить чанки, чьи эмбеддинги наиболее похожи на эмбеддинг запроса.\n",
        "    *   *Оптимизация:* Если параметры чанкирования не изменились, используем уже созданные чанки, эмбеддинги и индекс из предыдущей итерации для экономии времени и API-запросов.\n",
        "\n",
        "2.  **Тестирование стратегий RAG (Шаг 8.2):**\n",
        "    *   Для текущего значения `top_k` выполняем каждую из определённых стратегий RAG:\n",
        "        *   **Simple RAG:** Извлекаем `top_k` чанков на основе схожести с исходным запросом.\n",
        "        *   **Query Rewrite RAG:** Сначала просим LLM переформулировать исходный запрос для более эффективного поиска. Затем извлекаем `top_k` чанков по схожести с *переформулированным* запросом.\n",
        "        *   **Rerank RAG (симуляция):** Сначала извлекаем больше чанков (`top_k * RERANK_RETRIEVAL_MULTIPLIER`). Затем *симулируем* повторное ранжирование, просто выбирая топ-`top_k` результатов из этого большего множества. (В реальной реализации для этого используется отдельная модель для ранжирования).\n",
        "\n",
        "3.  **Оценка и сохранение результатов (Шаг 8.3 внутри `run_and_evaluate`):**\n",
        "    *   Для каждого запуска стратегии:\n",
        "        *   **Извлечение:** Находим индексы релевантных чанков через индекс FAISS.\n",
        "        *   **Генерация:** Формируем промпт с выбранными чанками в качестве контекста и *исходным* `test_query`. Отправляем это в модель генерации Nebius (`NEBIUS_GENERATION_MODEL`) для получения финального ответа.\n",
        "        *   **Оценка (Faithfulness):** Используем оценщик LLM (`NEBIUS_EVALUATION_MODEL`) с `FAITHFULNESS_PROMPT`, чтобы оценить, насколько хорошо сгенерированный ответ соответствует `true_answer_for_query`.\n",
        "        *   **Оценка (Relevancy):** Используем оценщик LLM с `RELEVANCY_PROMPT`, чтобы оценить, насколько хорошо сгенерированный ответ отвечает на `test_query`.\n",
        "        *   **Оценка (Similarity):** Используем функцию `calculate_cosine_similarity` для оценки семантического сходства между сгенерированным ответом и `true_answer_for_query`.\n",
        "        *   **Расчёт среднего балла:** Вычисляем среднее значение по оценкам Faithfulness, Relevancy и Similarity.\n",
        "        *   **Сохранение:** Записываем все параметры (`chunk_size`, `overlap`, `top_k`, `strategy`), извлечённые индексы, переформулированный запрос (если есть), сгенерированный ответ, отдельные оценки, средний балл и время выполнения для этого запуска.\n",
        "\n",
        "Для внешнего цикла по параметрам используем `tqdm` для отображения прогресс-бара.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "main-loop-exec-v5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615,
          "referenced_widgets": [
            "c3b6095887754e6f99a3f7a2d23be038",
            "304951d910304ea9bd2823a8407e8bea",
            "7194f9ff0cd6423ab0a2f4fff6a4f8ca",
            "dab657d30fd84e2486b1986aaaac3597",
            "20000cca021048ac8202e3d07603c0ad",
            "e6865f334b204f55bbcb183a3d00f671",
            "65a2f579207c41a4954b682f10441063",
            "4652f535a3084cdbb53e3938fdb44cf0",
            "b10b9731222b415a9c3036ded4ae7ace",
            "90207a7b70a8468ca03d0364f102388f",
            "f874f739a7664d829fc60c66dfc200e3"
          ]
        },
        "id": "main-loop-exec-v5",
        "outputId": "a3ac3972-bc92-446c-f82e-06cc2a976a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Запуск эксперимента RAG ===\n",
            "\n",
            "Всего комбинаций параметров для тестирования: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Тестирование конфигураций:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3b6095887754e6f99a3f7a2d23be038"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Готово: Simple RAG (C=150, O=30, K=3). Средний балл=0.89, Время=7.41с\n",
            "      Внимание: Ошибка разбора Relevancy score для Query Rewrite RAG - could not convert string to float: '0.9\\n\\nThe AI response is highly relevant'. Оценка выставлена в 0.0\n",
            "    Готово: Query Rewrite RAG (C=150, O=30, K=3). Средний балл=0.59, Время=4.94с\n",
            "    Готово: Rerank RAG (Simulated) (C=150, O=30, K=3). Средний балл=0.90, Время=7.27с\n",
            "    Готово: Simple RAG (C=150, O=30, K=5). Средний балл=0.89, Время=6.04с\n",
            "    Готово: Query Rewrite RAG (C=150, O=30, K=5). Средний балл=0.89, Время=14.73с\n",
            "    Готово: Rerank RAG (Simulated) (C=150, O=30, K=5). Средний балл=0.89, Время=10.75с\n",
            "    Готово: Simple RAG (C=150, O=50, K=3). Средний балл=0.89, Время=6.65с\n",
            "    Готово: Query Rewrite RAG (C=150, O=50, K=3). Средний балл=0.89, Время=6.43с\n",
            "    Готово: Rerank RAG (Simulated) (C=150, O=50, K=3). Средний балл=0.90, Время=6.64с\n",
            "    Готово: Simple RAG (C=150, O=50, K=5). Средний балл=0.89, Время=8.76с\n",
            "    Готово: Query Rewrite RAG (C=150, O=50, K=5). Средний балл=0.89, Время=6.33с\n",
            "    Готово: Rerank RAG (Simulated) (C=150, O=50, K=5). Средний балл=0.89, Время=6.49с\n",
            "    Готово: Simple RAG (C=250, O=30, K=3). Средний балл=0.90, Время=6.27с\n",
            "    Готово: Query Rewrite RAG (C=250, O=30, K=3). Средний балл=0.89, Время=9.10с\n",
            "    Готово: Rerank RAG (Simulated) (C=250, O=30, K=3). Средний балл=0.89, Время=8.18с\n",
            "    Готово: Simple RAG (C=250, O=30, K=5). Средний балл=0.89, Время=7.67с\n",
            "    Готово: Query Rewrite RAG (C=250, O=30, K=5). Средний балл=0.89, Время=7.97с\n",
            "    Готово: Rerank RAG (Simulated) (C=250, O=30, K=5). Средний балл=0.89, Время=10.55с\n",
            "    Готово: Simple RAG (C=250, O=50, K=3). Средний балл=0.89, Время=9.98с\n",
            "    Готово: Query Rewrite RAG (C=250, O=50, K=3). Средний балл=0.88, Время=5.50с\n",
            "    Готово: Rerank RAG (Simulated) (C=250, O=50, K=3). Средний балл=0.90, Время=5.99с\n",
            "    Готово: Simple RAG (C=250, O=50, K=5). Средний балл=0.89, Время=5.63с\n",
            "    Готово: Query Rewrite RAG (C=250, O=50, K=5). Средний балл=0.89, Время=6.45с\n",
            "    Готово: Rerank RAG (Simulated) (C=250, O=50, K=5). Средний балл=0.90, Время=6.74с\n",
            "\n",
            "=== Экспериментальный цикл RAG завершён ===\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "# Список для хранения детальных результатов каждого эксперимента\n",
        "all_results = []\n",
        "\n",
        "# --- Переменные кэша для чанкирования/эмбеддинга/индексации ---\n",
        "# Эти переменные помогают избежать лишних вычислений, если меняется только 'top_k'.\n",
        "last_chunk_size = -1      # Хранит chunk_size, использованный в предыдущей итерации\n",
        "last_overlap = -1         # Хранит chunk_overlap, использованный в предыдущей итерации\n",
        "current_index = None      # Содержит текущий индекс FAISS\n",
        "current_chunks = []       # Содержит список чанков для текущих настроек\n",
        "current_embeddings = None # Содержит массив эмбеддингов для текущих чанков\n",
        "\n",
        "# Проверяем, был ли клиент Nebius инициализирован перед началом работы\n",
        "if not client:\n",
        "    print(\"ОСТАНОВКА: Клиент Nebius AI не инициализирован. Невозможно запустить эксперимент.\")\n",
        "else:\n",
        "    print(\"=== Запуск эксперимента RAG ===\\n\")\n",
        "\n",
        "    # Создаем все возможные комбинации настраиваемых параметров\n",
        "    param_combinations = list(itertools.product(\n",
        "        CHUNK_SIZES_TO_TEST,\n",
        "        CHUNK_OVERLAPS_TO_TEST,\n",
        "        RETRIEVAL_TOP_K_TO_TEST\n",
        "    ))\n",
        "\n",
        "    print(f\"Всего комбинаций параметров для тестирования: {len(param_combinations)}\")\n",
        "\n",
        "    # --- Основной цикл ---\n",
        "    # Перебираем каждую комбинацию (chunk_size, chunk_overlap, top_k)\n",
        "    # Используем tqdm для отображения прогресс-бара.\n",
        "    for chunk_size, chunk_overlap, top_k in tqdm(param_combinations, desc=\"Тестирование конфигураций\"):\n",
        "\n",
        "        # --- 8.1 Обработка конфигурации чанкирования ---\n",
        "        # Проверяем, изменились ли параметры чанкирования, чтобы решить, нужно ли пересчитывать.\n",
        "        if chunk_size != last_chunk_size or chunk_overlap != last_overlap:\n",
        "            # Раскомментируйте строку ниже для подробного логирования\n",
        "            # print(f\"\\n--- Новая конфигурация чанкирования: Size={chunk_size}, Overlap={chunk_overlap} ---\")\n",
        "\n",
        "            # Обновляем кэш-переменные\n",
        "            last_chunk_size, last_overlap = chunk_size, chunk_overlap\n",
        "            # Сбрасываем индекс, чанки и эмбеддинги для новой конфигурации\n",
        "            current_index = None\n",
        "            current_chunks = []\n",
        "            current_embeddings = None\n",
        "\n",
        "            # --- 8.1a: Чанкирование ---\n",
        "            # Применяем функцию chunk_text к каждому документу корпуса\n",
        "            try:\n",
        "                # print(\"  Нарезка документов на чанки...\") # Раскомментируйте для подробного логирования\n",
        "                temp_chunks = []\n",
        "                for doc_index, doc in enumerate(corpus_texts):\n",
        "                    doc_chunks = chunk_text(doc, chunk_size, chunk_overlap)\n",
        "                    if not doc_chunks:\n",
        "                         print(f\"  Внимание: Не удалось создать чанки для документа {doc_index} с размером={chunk_size}, перекрытием={chunk_overlap}. Пропускаем документ.\")\n",
        "                         continue\n",
        "                    temp_chunks.extend(doc_chunks)\n",
        "\n",
        "                current_chunks = temp_chunks\n",
        "                if not current_chunks:\n",
        "                    # Если вообще не удалось создать ни одного чанка (например, из-за неверных параметров или пустого корпуса)\n",
        "                    raise ValueError(\"Для данной конфигурации не создано ни одного чанка.\")\n",
        "                # print(f\"    Создано всего чанков: {len(current_chunks)}.\") # Раскомментируйте для подробного логирования\n",
        "            except Exception as e:\n",
        "                 print(f\"    ОШИБКА при нарезке чанков для Size={chunk_size}, Overlap={chunk_overlap}: {e}. Пропускаем эту конфигурацию.\")\n",
        "                 last_chunk_size, last_overlap = -1, -1 # Сброс состояния кэша\n",
        "                 continue # Переходим к следующей комбинации параметров\n",
        "\n",
        "            # --- 8.1b: Эмбеддинг ---\n",
        "            # Генерируем эмбеддинги для всех чанков через API Nebius.\n",
        "            # print(\"  Генерация эмбеддингов...\") # Раскомментируйте для подробного логирования\n",
        "            try:\n",
        "                batch_size = 32 # Обрабатываем чанки пакетами, чтобы не перегружать API.\n",
        "                temp_embeddings = [] # Временный список для хранения эмбеддингов\n",
        "\n",
        "                # Обрабатываем чанки пакетами\n",
        "                for i in range(0, len(current_chunks), batch_size):\n",
        "                    batch_texts = current_chunks[i : min(i + batch_size, len(current_chunks))]\n",
        "                    # Запрос к API Nebius для текущего пакета\n",
        "                    response = client.embeddings.create(model=NEBIUS_EMBEDDING_MODEL, input=batch_texts)\n",
        "                    # Извлекаем эмбеддинги из ответа API\n",
        "                    batch_embeddings = [item.embedding for item in response.data]\n",
        "                    temp_embeddings.extend(batch_embeddings)\n",
        "                    time.sleep(0.05) # Добавляем небольшую задержку между пакетами из вежливости к API.\n",
        "\n",
        "                # Преобразуем список эмбеддингов в единый массив NumPy\n",
        "                current_embeddings = np.array(temp_embeddings)\n",
        "                # Базовая проверка массива эмбеддингов\n",
        "                if current_embeddings.ndim != 2 or current_embeddings.shape[0] != len(current_chunks):\n",
        "                    raise ValueError(f\"Форма массива эмбеддингов не совпадает. Ожидалось ({len(current_chunks)}, dim), получено {current_embeddings.shape}\")\n",
        "                # print(f\"    Сгенерировано эмбеддингов: {current_embeddings.shape[0]} (размерность: {current_embeddings.shape[1]}).\") # Раскомментируйте для подробного логирования\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    ОШИБКА при генерации эмбеддингов для Size={chunk_size}, Overlap={chunk_overlap}: {e}. Пропускаем эту конфигурацию чанков.\")\n",
        "                # Сбрасываем переменные кэша, чтобы показать неудачу для этой настройки\n",
        "                last_chunk_size, last_overlap = -1, -1\n",
        "                current_chunks = []\n",
        "                current_embeddings = None\n",
        "                continue # Пропускаем к следующей комбинации параметров\n",
        "\n",
        "            # --- 8.1c: Индексация ---\n",
        "            # Строим индекс FAISS для быстрого поиска по сходству.\n",
        "            # print(\"  Строим поисковый индекс FAISS...\") # Раскомментируйте для подробного логирования\n",
        "            try:\n",
        "                embedding_dim = current_embeddings.shape[1] # Получаем размерность эмбеддингов\n",
        "                # Используем IndexFlatL2, который реализует точный поиск по L2 (евклидово расстояние).\n",
        "                # Для современных эмбеддинговых моделей часто лучше работает косинусное сходство,\n",
        "                # но IndexFlatIP (Inner Product) у FAISS с нормализованными векторами эквивалентен L2.\n",
        "                current_index = faiss.IndexFlatL2(embedding_dim)\n",
        "                # Добавляем эмбеддинги чанков в индекс. FAISS требует тип float32.\n",
        "                current_index.add(current_embeddings.astype('float32'))\n",
        "\n",
        "                if current_index.ntotal == 0:\n",
        "                     raise ValueError(\"Индекс FAISS пуст после добавления векторов. Векторы не были добавлены.\")\n",
        "                # print(f\"    Индекс FAISS готов с {current_index.ntotal} векторами.\") # Раскомментируйте для подробного логирования\n",
        "            except Exception as e:\n",
        "                print(f\"    ОШИБКА при построении индекса FAISS для Size={chunk_size}, Overlap={chunk_overlap}: {e}. Пропускаем эту конфигурацию чанков.\")\n",
        "                # Сброс переменных для индикации неудачи\n",
        "                last_chunk_size, last_overlap = -1, -1\n",
        "                current_index = None\n",
        "                current_embeddings = None\n",
        "                current_chunks = []\n",
        "                continue # Переход к следующей комбинации параметров\n",
        "\n",
        "        # --- 8.2 Тестирование стратегий RAG для текущего Top-K ---\n",
        "        # Если дошли сюда — у нас валидные индекс и чанки для текущих chunk_size/overlap.\n",
        "\n",
        "        # Проверяем, действительно ли индекс и чанки доступны (для безопасности)\n",
        "        if current_index is None or not current_chunks:\n",
        "            print(f\"    ВНИМАНИЕ: Индекс или чанки недоступны для Size={chunk_size}, Overlap={chunk_overlap}. Пропускаем тест Top-K={top_k}.\")\n",
        "            continue\n",
        "\n",
        "        # --- 8.3 Запуск и оценка одной стратегии RAG ---\n",
        "        # Определяем вложенную функцию для основных шагов RAG (извлечение, генерация, оценка)\n",
        "        # Это позволяет не дублировать код для каждой стратегии.\n",
        "        def run_and_evaluate(strategy_name, query_to_use, k_retrieve, use_simulated_rerank=False):\n",
        "            # print(f\"    Запуск: {strategy_name} (k={k_retrieve}) ...\") # Раскомментируйте для подробного логирования\n",
        "            run_start_time = time.time() # Время старта для замера времени выполнения\n",
        "\n",
        "            # Словарь для хранения результатов конкретного запуска\n",
        "            result = {\n",
        "                'chunk_size': chunk_size, 'overlap': chunk_overlap, 'top_k': k_retrieve,\n",
        "                'strategy': strategy_name,\n",
        "                'retrieved_indices': [], 'rewritten_query': None, 'answer': 'Error: Execution Failed',\n",
        "                'faithfulness': 0.0, 'relevancy': 0.0, 'similarity_score': 0.0, 'avg_score': 0.0,\n",
        "                'time_sec': 0.0\n",
        "            }\n",
        "            # Сохраняем переписанный запрос, если применимо\n",
        "            if strategy_name == \"Query Rewrite RAG\":\n",
        "                result['rewritten_query'] = query_to_use\n",
        "\n",
        "            try:\n",
        "                # --- Извлечение ---\n",
        "                k_for_search = k_retrieve # Сколько чанков извлекать изначально\n",
        "                if use_simulated_rerank:\n",
        "                    # Для симулированного rerank извлекаем больше кандидатов сначала\n",
        "                    k_for_search = k_retrieve * RERANK_RETRIEVAL_MULTIPLIER\n",
        "                    # print(f\"      Rerank: Первичное извлечение {k_for_search} кандидатов.\") # Раскомментируйте для логирования\n",
        "\n",
        "                # 1. Эмбеддинг запроса (оригинального или переписанного)\n",
        "                query_embedding_response = client.embeddings.create(model=NEBIUS_EMBEDDING_MODEL, input=[query_to_use])\n",
        "                query_embedding = query_embedding_response.data[0].embedding\n",
        "                query_vector = np.array([query_embedding]).astype('float32') # FAISS требует float32\n",
        "\n",
        "                # 2. Поиск в индексе FAISS\n",
        "                # Гарантируем, что k не превышает количество элементов в индексе\n",
        "                actual_k = min(k_for_search, current_index.ntotal)\n",
        "                if actual_k == 0:\n",
        "                    raise ValueError(\"Индекс пуст или k_for_search равно нулю, поиск невозможен.\")\n",
        "\n",
        "                # `current_index.search` возвращает расстояния и индексы ближайших соседей\n",
        "                distances, indices = current_index.search(query_vector, actual_k)\n",
        "\n",
        "                # 3. Обработка извлечённых индексов\n",
        "                # Индексы могут содержать -1 если найдено меньше, чем 'actual_k' (для IndexFlatL2 не бывает, если k <= ntotal)\n",
        "                retrieved_indices_all = indices[0]\n",
        "                valid_indices = retrieved_indices_all[retrieved_indices_all != -1].tolist()\n",
        "\n",
        "                # 4. Симулируем reranking (если применимо)\n",
        "                # В этой симуляции просто берём топ k_retrieve результатов из большего множества.\n",
        "                if use_simulated_rerank:\n",
        "                    final_indices = valid_indices[:k_retrieve]\n",
        "                    # print(f\"      Rerank: Выбрано топ {len(final_indices)} индексов после симулированного rerank.\") # Логирование\n",
        "                else:\n",
        "                    final_indices = valid_indices # Используем все валидные индексы до k_retrieve\n",
        "\n",
        "                result['retrieved_indices'] = final_indices\n",
        "\n",
        "                # 5. Получаем текстовые чанки по финальным индексам\n",
        "                retrieved_chunks = [current_chunks[i] for i in final_indices]\n",
        "\n",
        "                # Обрабатываем случай, когда ни одного чанка не найдено (редко, но возможно)\n",
        "                if not retrieved_chunks:\n",
        "                    print(f\"      Внимание: Не найдено релевантных чанков для {strategy_name} (C={chunk_size}, O={chunk_overlap}, K={k_retrieve}). Ответ будет соответствующим.\")\n",
        "                    result['answer'] = \"По запросу не найдено релевантного контекста в документах.\"\n",
        "                    # Оценки оставляем по умолчанию (0.0), т.к. не было ответа из контекста\n",
        "                else:\n",
        "                    # --- Генерация ---\n",
        "                    # Собираем чанки в единую строку-контекст\n",
        "                    context_str = \"\\n\\n\".join(retrieved_chunks)\n",
        "\n",
        "                    # Системный промпт для LLM генерации\n",
        "                    sys_prompt_gen = \"You are a helpful AI assistant. Answer the user's query based strictly on the provided context. If the context doesn't contain the answer, state that clearly. Be concise.\"\n",
        "\n",
        "                    # Собираем пользовательский промпт с контекстом и оригинальным запросом\n",
        "                    # Здесь важно использовать именно оригинальный запрос для генерации финального ответа, даже если для извлечения использовался переписанный.\n",
        "                    user_prompt_gen = f\"Context:\\n------\\n{context_str}\\n------\\n\\nQuery: {test_query}\\n\\nAnswer:\"\n",
        "\n",
        "                    # Запрос к Nebius generation model\n",
        "                    gen_response = client.chat.completions.create(\n",
        "                        model=NEBIUS_GENERATION_MODEL,\n",
        "                        messages=[\n",
        "                            {\"role\": \"system\", \"content\": sys_prompt_gen},\n",
        "                            {\"role\": \"user\", \"content\": user_prompt_gen}\n",
        "                        ],\n",
        "                        temperature=GENERATION_TEMPERATURE,\n",
        "                        max_tokens=GENERATION_MAX_TOKENS,\n",
        "                        top_p=GENERATION_TOP_P\n",
        "                    )\n",
        "                    # Извлекаем сгенерированный текст-ответ\n",
        "                    generated_answer = gen_response.choices[0].message.content.strip()\n",
        "                    result['answer'] = generated_answer\n",
        "                    # print(f\"      Сгенерированный ответ: {generated_answer[:100].replace('\\n', ' ')}...\") # Опционально\n",
        "\n",
        "                    # --- Оценка ---\n",
        "                    # Оцениваем сгенерированный ответ по Faithfulness, Relevancy, Similarity\n",
        "                    # print(f\"      Оценка ответа... (Faithfulness, Relevancy, Similarity)\") # Опционально\n",
        "\n",
        "                    # Параметры для оценки (температура — 0.0 для детерминированности)\n",
        "                    eval_params = {'model': NEBIUS_EVALUATION_MODEL, 'temperature': 0.0, 'max_tokens': 10}\n",
        "\n",
        "                    # 1. Оценка Faithfulness\n",
        "                    prompt_f = FAITHFULNESS_PROMPT.format(question=test_query, response=generated_answer, true_answer=true_answer_for_query)\n",
        "                    try:\n",
        "                        resp_f = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt_f}], **eval_params)\n",
        "                        # Парсим оценку, приводим к диапазону 0.0–1.0\n",
        "                        result['faithfulness'] = max(0.0, min(1.0, float(resp_f.choices[0].message.content.strip())))\n",
        "                    except Exception as eval_e:\n",
        "                        print(f\"      Внимание: Ошибка разбора Faithfulness score для {strategy_name} - {eval_e}. Оценка выставлена в 0.0\")\n",
        "                        result['faithfulness'] = 0.0\n",
        "\n",
        "                    # 2. Оценка Relevancy\n",
        "                    prompt_r = RELEVANCY_PROMPT.format(question=test_query, response=generated_answer)\n",
        "                    try:\n",
        "                        resp_r = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt_r}], **eval_params)\n",
        "                        # Парсим оценку, приводим к диапазону 0.0–1.0\n",
        "                        result['relevancy'] = max(0.0, min(1.0, float(resp_r.choices[0].message.content.strip())))\n",
        "                    except Exception as eval_e:\n",
        "                        print(f\"      Внимание: Ошибка разбора Relevancy score для {strategy_name} - {eval_e}. Оценка выставлена в 0.0\")\n",
        "                        result['relevancy'] = 0.0\n",
        "\n",
        "                    # 3. Расчет Similarity\n",
        "                    result['similarity_score'] = calculate_cosine_similarity(\n",
        "                        generated_answer,\n",
        "                        true_answer_for_query,\n",
        "                        client,\n",
        "                        NEBIUS_EMBEDDING_MODEL\n",
        "                    )\n",
        "\n",
        "                    # 4. Вычисляем средний балл (Faithfulness, Relevancy, Similarity)\n",
        "                    result['avg_score'] = (result['faithfulness'] + result['relevancy'] + result['similarity_score']) / 3.0\n",
        "\n",
        "            except Exception as e:\n",
        "                # Обработка любых неожиданных ошибок в процессе извлечения/генерации/оценки\n",
        "                error_message = f\"ОШИБКА при {strategy_name} (C={chunk_size}, O={chunk_overlap}, K={k_retrieve}): {str(e)[:200]}...\"\n",
        "                print(f\"    {error_message}\")\n",
        "                result['answer'] = error_message # Сохраняем ошибку в поле ответа\n",
        "                # Оставляем оценки в состоянии по умолчанию (0.0)\n",
        "                result['faithfulness'] = 0.0\n",
        "                result['relevancy'] = 0.0\n",
        "                result['similarity_score'] = 0.0\n",
        "                result['avg_score'] = 0.0\n",
        "\n",
        "            # Записываем общее время выполнения для данного запуска\n",
        "            run_end_time = time.time()\n",
        "            result['time_sec'] = run_end_time - run_start_time\n",
        "\n",
        "            # Печатаем краткую информацию о запуске (для отслеживания прогресса)\n",
        "            print(f\"    Готово: {strategy_name} (C={chunk_size}, O={chunk_overlap}, K={k_retrieve}). Средний балл={result['avg_score']:.2f}, Время={result['time_sec']:.2f}с\")\n",
        "            return result\n",
        "        # --- Конец вложенной функции run_and_evaluate ---\n",
        "\n",
        "        # --- Выполняем стратегии RAG с помощью run_and_evaluate ---\n",
        "\n",
        "        # Стратегия 1: Simple RAG (используем оригинальный запрос для поиска)\n",
        "        result_simple = run_and_evaluate(\"Simple RAG\", test_query, top_k)\n",
        "        all_results.append(result_simple)\n",
        "\n",
        "        # Стратегия 2: Query Rewrite RAG\n",
        "        rewritten_q = test_query # По умолчанию используем оригинальный запрос, если rewrite не удался\n",
        "        try:\n",
        "             # print(\"    Переписываем запрос для Rewrite RAG...\") # Опционально\n",
        "             # Промпты для задачи переписывания запроса\n",
        "             sys_prompt_rw = \"You are an expert query optimizer. Rewrite the user's query to be ideal for vector database retrieval. Focus on key entities, concepts, and relationships. Remove conversational fluff. Output ONLY the rewritten query text.\"\n",
        "             user_prompt_rw = f\"Original Query: {test_query}\\n\\nRewritten Query:\"\n",
        "\n",
        "             # Запрос к LLM на переписывание запроса\n",
        "             resp_rw = client.chat.completions.create(\n",
        "                 model=NEBIUS_GENERATION_MODEL, # Для этой задачи тоже подойдёт модель генерации\n",
        "                 messages=[\n",
        "                     {\"role\": \"system\", \"content\": sys_prompt_rw},\n",
        "                     {\"role\": \"user\", \"content\": user_prompt_rw}\n",
        "                 ],\n",
        "                 temperature=0.1, # Низкая температура для лаконичного результата\n",
        "                 max_tokens=100,\n",
        "                 top_p=0.9\n",
        "             )\n",
        "             # Очищаем ответ LLM, чтобы получить только текст запроса\n",
        "             candidate_q = resp_rw.choices[0].message.content.strip()\n",
        "             # Убираем возможные префиксы типа \"Rewritten Query:\" или \"Query:\"\n",
        "             candidate_q = re.sub(r'^(rewritten query:|query:)\\s*', '', candidate_q, flags=re.IGNORECASE).strip('\"')\n",
        "\n",
        "             # Используем переписанный запрос, только если он реально отличается и не слишком короткий\n",
        "             if candidate_q and len(candidate_q) > 5 and candidate_q.lower() != test_query.lower():\n",
        "                 rewritten_q = candidate_q\n",
        "                 # print(f\"      Используем переписанный запрос: '{rewritten_q}'\") # Опционально\n",
        "             # else:\n",
        "                 # print(\"      Переписывание не удалось или результат такой же, как оригинал. Используем оригинальный запрос.\") # Опционально\n",
        "        except Exception as e:\n",
        "             print(f\"    Внимание: Ошибка при переписывании запроса: {e}. Используем оригинальный запрос.\")\n",
        "             rewritten_q = test_query # В случае ошибки возвращаемся к оригинальному запросу\n",
        "\n",
        "        # Оцениваем результат с (возможно) переписанным запросом для поиска\n",
        "        result_rewrite = run_and_evaluate(\"Query Rewrite RAG\", rewritten_q, top_k)\n",
        "        all_results.append(result_rewrite)\n",
        "\n",
        "        # Стратегия 3: Rerank RAG (симуляция)\n",
        "        # Используем оригинальный запрос для поиска, но симулируем процесс ранжирования\n",
        "        result_rerank = run_and_evaluate(\"Rerank RAG (Simulated)\", test_query, top_k, use_simulated_rerank=True)\n",
        "        all_results.append(result_rerank)\n",
        "\n",
        "    print(\"\\n=== Экспериментальный цикл RAG завершён ===\")\n",
        "    print(\"-\" * 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "analysis-v5",
      "metadata": {
        "id": "analysis-v5"
      },
      "source": [
        "### 9. Анализ: просмотр результатов\n",
        "\n",
        "Теперь, когда экспериментальный цикл завершён и в `all_results` содержатся данные каждого прогона, мы используем библиотеку Pandas для анализа результатов.\n",
        "\n",
        "1.  **Создание DataFrame:** Преобразуем список словарей результатов (`all_results`) в DataFrame Pandas для удобной обработки и просмотра.\n",
        "2.  **Сортировка результатов:** Отсортируем DataFrame по `avg_score` (среднему значению Faithfulness, Relevancy и Similarity) по убыванию, чтобы лучшие конфигурации были вверху.\n",
        "3.  **Вывод топ-конфигураций:** Отобразим верхние N строк отсортированного DataFrame с ключевыми параметрами, оценками и сгенерированным ответом — это поможет быстро выделить наиболее перспективные настройки.\n",
        "4.  **Сводка лучшего запуска:** Напечатаем чёткое резюме единственной самой успешной конфигурации по среднему баллу: её параметры, индивидуальные оценки, затраченное время и полный сгенерированный ответ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "compare-results-v5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "compare-results-v5",
        "outputId": "0b3d5445-64a2-43ca-9dc9-f8a79c849c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Анализ результатов эксперимента ---\n",
            "Всего собрано результатов: 24\n",
            "\n",
            "--- Топ-10 конфигураций (отсортировано по среднему баллу) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   chunk_size  overlap  top_k                strategy  avg_score  \\\n",
              "0         150       30      3  Rerank RAG (Simulated)   0.897648   \n",
              "1         250       50      5  Rerank RAG (Simulated)   0.897204   \n",
              "2         150       50      3  Rerank RAG (Simulated)   0.895689   \n",
              "3         250       50      3  Rerank RAG (Simulated)   0.895561   \n",
              "4         250       30      3              Simple RAG   0.895335   \n",
              "5         150       50      3       Query Rewrite RAG   0.894385   \n",
              "6         250       30      3       Query Rewrite RAG   0.893745   \n",
              "7         250       50      3              Simple RAG   0.893461   \n",
              "8         150       50      3              Simple RAG   0.892797   \n",
              "9         150       30      5  Rerank RAG (Simulated)   0.892647   \n",
              "\n",
              "   faithfulness  relevancy  similarity_score   time_sec  \\\n",
              "0           0.9        1.0          0.792944   7.266874   \n",
              "1           0.9        1.0          0.791613   6.744190   \n",
              "2           0.9        1.0          0.787067   6.643735   \n",
              "3           0.9        1.0          0.786683   5.991125   \n",
              "4           0.9        1.0          0.786004   6.273028   \n",
              "5           0.9        1.0          0.783156   6.430842   \n",
              "6           0.9        1.0          0.781236   9.103239   \n",
              "7           0.9        1.0          0.780383   9.975372   \n",
              "8           0.9        1.0          0.778390   6.650850   \n",
              "9           0.9        1.0          0.777942  10.745529   \n",
              "\n",
              "                                                                                                                                                  answer  \n",
              "0  Solar power and hydropower differ significantly in consistency and environmental impact:\\n\\n**Consistency:**\\n- **Hydropower** is highly reliable ...  \n",
              "1  Solar power and hydropower differ significantly in consistency and environmental impact:\\n\\n- **Consistency**:  \\n  - **Solar Power**: Inconsisten...  \n",
              "2  **Consistency:**\\n- **Hydropower** is highly reliable and consistent, providing large-scale power 24/7, as it relies on the continuous flow of wat...  \n",
              "3  **Consistency:**\\n- **Hydropower** is highly reliable and consistent, providing large-scale power 24/7, as it relies on the continuous flow of wat...  \n",
              "4  **Consistency:**\\n- **Hydropower** is highly consistent and reliable, providing large-scale power 24/7, as it relies on the continuous flow of wat...  \n",
              "5  **Consistency:**\\n- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather conditions and...  \n",
              "6  **Consistency:**\\n- **Hydropower** is highly consistent and reliable, providing large-scale power 24/7, as it relies on the continuous flow of wat...  \n",
              "7  **Consistency:**\\n- **Hydropower:** Highly reliable and consistent, as it can generate electricity continuously as long as water flow is maintaine...  \n",
              "8  **Consistency:**\\n- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather conditions and...  \n",
              "9  **Consistency:**  \\n- **Solar Power:** Inconsistent due to dependence on weather and daylight. Requires storage solutions (e.g., batteries) for re...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e19ae820-71aa-4535-b48f-ca500b6cefbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk_size</th>\n",
              "      <th>overlap</th>\n",
              "      <th>top_k</th>\n",
              "      <th>strategy</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>relevancy</th>\n",
              "      <th>similarity_score</th>\n",
              "      <th>time_sec</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>Rerank RAG (Simulated)</td>\n",
              "      <td>0.897648</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.792944</td>\n",
              "      <td>7.266874</td>\n",
              "      <td>Solar power and hydropower differ significantly in consistency and environmental impact:\\n\\n**Consistency:**\\n- **Hydropower** is highly reliable ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>250</td>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>Rerank RAG (Simulated)</td>\n",
              "      <td>0.897204</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.791613</td>\n",
              "      <td>6.744190</td>\n",
              "      <td>Solar power and hydropower differ significantly in consistency and environmental impact:\\n\\n- **Consistency**:  \\n  - **Solar Power**: Inconsisten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>150</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>Rerank RAG (Simulated)</td>\n",
              "      <td>0.895689</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.787067</td>\n",
              "      <td>6.643735</td>\n",
              "      <td>**Consistency:**\\n- **Hydropower** is highly reliable and consistent, providing large-scale power 24/7, as it relies on the continuous flow of wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>250</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>Rerank RAG (Simulated)</td>\n",
              "      <td>0.895561</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.786683</td>\n",
              "      <td>5.991125</td>\n",
              "      <td>**Consistency:**\\n- **Hydropower** is highly reliable and consistent, providing large-scale power 24/7, as it relies on the continuous flow of wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>250</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>Simple RAG</td>\n",
              "      <td>0.895335</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.786004</td>\n",
              "      <td>6.273028</td>\n",
              "      <td>**Consistency:**\\n- **Hydropower** is highly consistent and reliable, providing large-scale power 24/7, as it relies on the continuous flow of wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>150</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>Query Rewrite RAG</td>\n",
              "      <td>0.894385</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.783156</td>\n",
              "      <td>6.430842</td>\n",
              "      <td>**Consistency:**\\n- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather conditions and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>250</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>Query Rewrite RAG</td>\n",
              "      <td>0.893745</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.781236</td>\n",
              "      <td>9.103239</td>\n",
              "      <td>**Consistency:**\\n- **Hydropower** is highly consistent and reliable, providing large-scale power 24/7, as it relies on the continuous flow of wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>250</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>Simple RAG</td>\n",
              "      <td>0.893461</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.780383</td>\n",
              "      <td>9.975372</td>\n",
              "      <td>**Consistency:**\\n- **Hydropower:** Highly reliable and consistent, as it can generate electricity continuously as long as water flow is maintaine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>150</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>Simple RAG</td>\n",
              "      <td>0.892797</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.778390</td>\n",
              "      <td>6.650850</td>\n",
              "      <td>**Consistency:**\\n- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather conditions and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "      <td>Rerank RAG (Simulated)</td>\n",
              "      <td>0.892647</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.777942</td>\n",
              "      <td>10.745529</td>\n",
              "      <td>**Consistency:**  \\n- **Solar Power:** Inconsistent due to dependence on weather and daylight. Requires storage solutions (e.g., batteries) for re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e19ae820-71aa-4535-b48f-ca500b6cefbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e19ae820-71aa-4535-b48f-ca500b6cefbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e19ae820-71aa-4535-b48f-ca500b6cefbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8fff4230-9ad7-4d7d-9cd9-17ab79d018d6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8fff4230-9ad7-4d7d-9cd9-17ab79d018d6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8fff4230-9ad7-4d7d-9cd9-17ab79d018d6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n--- \\u0410\\u043d\\u0430\\u043b\\u0438\\u0437 \\u0437\\u0430\\u0432\\u0435\\u0440\\u0448\\u0451\\u043d --- \\\")\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"chunk_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52,\n        \"min\": 150,\n        \"max\": 250,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          250,\n          150\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overlap\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 30,\n        \"max\": 50,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"strategy\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Rerank RAG (Simulated)\",\n          \"Simple RAG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0017400426174765207,\n        \"min\": 0.8926474148985615,\n        \"max\": 0.8976480060328912,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8927965908252785,\n          0.8972043909109417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1702778228589004e-16,\n        \"min\": 0.9,\n        \"max\": 0.9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005220127852429524,\n        \"min\": 0.7779422446956845,\n        \"max\": 0.7929440180986735,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7783897724758354\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.705168003294006,\n        \"min\": 5.991124868392944,\n        \"max\": 10.745529174804688,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6.650850057601929\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"**Consistency:**\\n- **Hydropower** is highly reliable and provides consistent, large-scale power, as it is not dependent on weather conditions and can operate 24/7.\\n- **Solar power** is less consistent due to its dependence on sunlight, which varies with weather and time of day. Storage solutions like batteries are essential to improve its reliability.\\n\\n**Environmental Impact:**\\n- **Hydropower** has significant environmental impacts, including ecosystem disruption and community displacement, especially with large dams. Run-of-river systems are less disruptive but still affect local ecosystems.\\n- **Solar power** is cleaner with minimal environmental impact during operation, though the production and disposal of PV panels can have environmental consequences. It does not disrupt ecosystems or displace communities. \\n\\nIn summary, hydropower is more consistent but has greater environmental impacts, while solar power is less consistent but generally has a lower environmental footprint.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Сводка по лучшей конфигурации ---\n",
            "Размер чанка: 150 слов\n",
            "Перекрытие: 30 слов\n",
            "Top-K извлечённых: 3 чанков\n",
            "Стратегия: Rerank RAG (Simulated)\n",
            "---> Средний балл (Faith+Rel+Sim): 0.898\n",
            "      (Достоверность: 0.900, Релевантность: 1.000, Сходство: 0.793)\n",
            "Затраченное время: 7.27 секунд\n",
            "\n",
            "Лучший сгенерированный ответ:\n",
            "Solar power and hydropower differ significantly in consistency and environmental impact:\n",
            "\n",
            "**Consistency:**\n",
            "- **Hydropower** is highly reliable and consistent, providing large-scale power 24/7, as it relies on the continuous flow of water.\n",
            "- **Solar power** is less consistent, as it depends on weather conditions and time of day. It requires storage solutions (like batteries) to ensure a steady supply.\n",
            "\n",
            "**Environmental Impact:**\n",
            "- **Hydropower** has significant environmental impacts, particularly from large dams, which can harm ecosystems, disrupt fish migration, and displace communities. Run-of-river systems are less disruptive but still affect local environments.\n",
            "- **Solar power** is cleaner with minimal environmental impact during operation. However, the production and disposal of PV panels can have environmental consequences, and large solar farms may alter land use.\n",
            "\n",
            "In summary, hydropower offers more consistent energy but with greater environmental disruption, while solar power is cleaner but less consistent without storage solutions.\n",
            "\n",
            "--- Анализ завершён --- \n"
          ]
        }
      ],
      "source": [
        "print(\"--- Анализ результатов эксперимента ---\")\n",
        "\n",
        "# Сначала проверяем, были ли вообще собраны какие-либо результаты\n",
        "if not all_results:\n",
        "    print(\"В ходе эксперимента не было получено результатов. Анализ невозможен.\")\n",
        "else:\n",
        "    # Преобразуем список словарей с результатами в DataFrame Pandas\n",
        "    results_df = pd.DataFrame(all_results)\n",
        "    print(f\"Всего собрано результатов: {len(results_df)}\")\n",
        "\n",
        "    # Сортируем DataFrame по столбцу 'avg_score' по убыванию (лучшие — сверху)\n",
        "    # Используем reset_index(drop=True) для чистого индекса с нуля после сортировки.\n",
        "    results_df_sorted = results_df.sort_values(by='avg_score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n--- Топ-10 конфигураций (отсортировано по среднему баллу) ---\")\n",
        "    # Определяем столбцы, которые хотим показать в итоговой таблице\n",
        "    display_cols = [\n",
        "        'chunk_size', 'overlap', 'top_k', 'strategy',\n",
        "        'avg_score', 'faithfulness', 'relevancy', 'similarity_score', # Добавлено similarity\n",
        "        'time_sec',\n",
        "        'answer' # Включаем ответ для качественной оценки лучших запусков\n",
        "    ]\n",
        "    # Исключаем те столбцы, которых нет (например, если была ошибка и не все были заполнены)\n",
        "    display_cols = [col for col in display_cols if col in results_df_sorted.columns]\n",
        "\n",
        "    # Показываем первые 10 строк отсортированного DataFrame по выбранным столбцам\n",
        "    # Функция display() даёт красивый вывод в Jupyter.\n",
        "    display(results_df_sorted[display_cols].head(10))\n",
        "\n",
        "    # --- Сводка по лучшей конфигурации ---\n",
        "    print(\"\\n--- Сводка по лучшей конфигурации ---\")\n",
        "    # Проверяем, что DataFrame после сортировки не пустой\n",
        "    if not results_df_sorted.empty:\n",
        "        # Берём первую строку (индекс 0) — это конфигурация с лучшим баллом\n",
        "        best_run = results_df_sorted.iloc[0]\n",
        "\n",
        "        # Выводим параметры и результаты лучшей конфигурации\n",
        "        print(f\"Размер чанка: {best_run.get('chunk_size', 'N/A')} слов\")\n",
        "        print(f\"Перекрытие: {best_run.get('overlap', 'N/A')} слов\")\n",
        "        print(f\"Top-K извлечённых: {best_run.get('top_k', 'N/A')} чанков\")\n",
        "        print(f\"Стратегия: {best_run.get('strategy', 'N/A')}\")\n",
        "        # Для устойчивости используем .get(col, default) — если столбца нет\n",
        "        avg_score = best_run.get('avg_score', 0.0)\n",
        "        faithfulness = best_run.get('faithfulness', 0.0)\n",
        "        relevancy = best_run.get('relevancy', 0.0)\n",
        "        similarity = best_run.get('similarity_score', 0.0)\n",
        "        time_sec = best_run.get('time_sec', 0.0)\n",
        "        best_answer = best_run.get('answer', 'N/A')\n",
        "\n",
        "        print(f\"---> Средний балл (Faith+Rel+Sim): {avg_score:.3f}\")\n",
        "        print(f\"      (Достоверность: {faithfulness:.3f}, Релевантность: {relevancy:.3f}, Сходство: {similarity:.3f})\")\n",
        "        print(f\"Затраченное время: {time_sec:.2f} секунд\")\n",
        "        print(f\"\\nЛучший сгенерированный ответ:\")\n",
        "        # Печатаем полный ответ, сгенерированный лучшей конфигурацией\n",
        "        print(best_answer)\n",
        "    else:\n",
        "        # Обработка случая, когда не было ни одного валидного результата\n",
        "        print(\"Не удалось определить лучшую конфигурацию (не найдено валидных результатов).\")\n",
        "\n",
        "print(\"\\n--- Анализ завершён --- \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion-v5",
      "metadata": {
        "id": "conclusion-v5"
      },
      "source": [
        "### 10. Выводы: Что мы узнали?\n",
        "\n",
        "Мы успешно построили и выполнили сквозной пайплайн для экспериментов с различными конфигурациями RAG и оценки их эффективности по нескольким метрикам на платформе Nebius AI.\n",
        "\n",
        "Анализируя таблицу результатов и сводку лучшей конфигурации выше, мы можем сделать выводы, актуальные именно для *нашего выбранного корпуса, запроса и моделей*.\n",
        "\n",
        "**Вопросы для размышления:**\n",
        "\n",
        "*   **Влияние нарезки на чанки:** Какой именно `chunk_size` или `overlap` чаще давал более высокие средние оценки? Почему небольшие чанки могут лучше захватывать отдельные факты, а большие — давать больше контекста? Как перекрытие повлияло на результаты?\n",
        "*   **Количество извлекаемых чанков (`top_k`):** Как увеличение `top_k` отразилось на оценках? Приводило ли извлечение большего числа чанков всегда к лучшим ответам, или иногда добавляло \"шум\" и нерелевантную информацию, снижая достоверность или сходство?\n",
        "*   **Сравнение стратегий:** Давали ли стратегии 'Query Rewrite' или 'Rerank (Simulated)' стабильное преимущество перед 'Simple RAG' по среднему баллу? Было ли улучшение достаточно значимым, чтобы оправдать дополнительные шаги (например, лишний вызов LLM для переписывания запроса, большее первоначальное извлечение для rerank)?\n",
        "*   **Метрики оценки:**\n",
        "    *   Посмотрите на 'Лучший ответ' и сравните его с `true_answer_for_query`. Насколько отдельные оценки (Faithfulness, Relevancy, Similarity) отражают ваше субъективное восприятие качества?\n",
        "    *   Всегда ли высокая схожесть коррелировала с высокой достоверностью? Может ли ответ быть похожим, но недостоверным, или достоверным, но непохожим?\n",
        "    *   Насколько надёжной вам кажется автоматическая оценка LLM (Faithfulness, Relevancy) по сравнению с более объективной косинусной мерой? Каковы потенциальные ограничения LLM-оценки (например, чувствительность к формулировке промпта, \"предвзятость\" модели)?\n",
        "*   **Общая производительность:** Получилась ли у какой-либо конфигурации почти идеальная средняя оценка? Что может мешать получить идеальный результат (например, ограничения исходных документов, неоднозначность языка, неидеальный поиск)?\n",
        "\n",
        "**Главный вывод:** Оптимизация системы RAG — это итеративный процесс. Лучшая конфигурация часто сильно зависит от конкретного датасета, типа пользовательских запросов, выбранных моделей эмбеддинга и LLM, а также критериев оценки. Системный эксперимент, как показано в этом ноутбуке, крайне важен для поиска оптимальных настроек под свою задачу.\n",
        "\n",
        "**Возможные следующие шаги и направления развития:**\n",
        "\n",
        "*   **Расширить диапазон параметров:** Попробовать больше значений для `chunk_size`, `overlap` и `top_k`.\n",
        "*   **Разные типы запросов:** Протестировать те же конфигурации на других типах вопросов (например, факт, сравнение, саммари), чтобы посмотреть, как меняется эффективность.\n",
        "*   **Больше/иной корпус:** Использовать более объёмную или тематическую базу знаний.\n",
        "*   **Реализовать настоящий rerank:** Заменить симулированное ранжирование на полноценную модель-кросс-энкодер (например, из Hugging Face Transformers или Cohere Rerank) для повторной оценки релевантности документов.\n",
        "*   **Альтернативные модели:** Поэкспериментировать с разными моделями Nebius AI для эмбеддинга, генерации или оценки.\n",
        "*   **Продвинутое чанкирование:** Опробовать более сложные стратегии нарезки (например, рекурсивное разбиение по символам, семантическое чанкирование).\n",
        "*   **Человеческая оценка:** Добавить экспертную оценку к автоматическим метрикам для более глубокого анализа качества ответов."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8XlfunVwopF"
      },
      "id": "G8XlfunVwopF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv-best-rag-finder",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3b6095887754e6f99a3f7a2d23be038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_304951d910304ea9bd2823a8407e8bea",
              "IPY_MODEL_7194f9ff0cd6423ab0a2f4fff6a4f8ca",
              "IPY_MODEL_dab657d30fd84e2486b1986aaaac3597"
            ],
            "layout": "IPY_MODEL_20000cca021048ac8202e3d07603c0ad"
          }
        },
        "304951d910304ea9bd2823a8407e8bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6865f334b204f55bbcb183a3d00f671",
            "placeholder": "​",
            "style": "IPY_MODEL_65a2f579207c41a4954b682f10441063",
            "value": "Тестирование конфигураций: 100%"
          }
        },
        "7194f9ff0cd6423ab0a2f4fff6a4f8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4652f535a3084cdbb53e3938fdb44cf0",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b10b9731222b415a9c3036ded4ae7ace",
            "value": 8
          }
        },
        "dab657d30fd84e2486b1986aaaac3597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90207a7b70a8468ca03d0364f102388f",
            "placeholder": "​",
            "style": "IPY_MODEL_f874f739a7664d829fc60c66dfc200e3",
            "value": " 8/8 [03:13&lt;00:00, 22.85s/it]"
          }
        },
        "20000cca021048ac8202e3d07603c0ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6865f334b204f55bbcb183a3d00f671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a2f579207c41a4954b682f10441063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4652f535a3084cdbb53e3938fdb44cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b10b9731222b415a9c3036ded4ae7ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90207a7b70a8468ca03d0364f102388f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f874f739a7664d829fc60c66dfc200e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}